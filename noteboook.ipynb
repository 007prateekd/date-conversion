{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import date\n",
    "import calendar\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, RepeatVector\n",
    "from tensorflow.keras.optimizers import Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_dates(n_dates):\n",
    "    min_date = date(1000, 1, 1).toordinal()\n",
    "    max_date = date(9999, 12, 31).toordinal()\n",
    "\n",
    "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "\n",
    "    x = [dt.strftime(\"%B %d, %Y\") for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "    return x, y"
   ]
  },
  {
   "source": [
    "MONTHS = calendar.month_name[1:13]\n",
    "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
    "INPUT_CHARS"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHARS = \"0123456789-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
    "    return [chars.index(c) for c in date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
    "    X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
    "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
    "    return (X + 1).to_tensor()\n",
    "\n",
    "def create_dataset(n_dates):\n",
    "    x, y = random_dates(n_dates)\n",
    "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = create_dataset(10000)\n",
    "X_valid, Y_valid = create_dataset(2000)\n",
    "X_test, Y_test = create_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "max_output_length = Y_train.shape[1]\n",
    "\n",
    "encoder = Sequential([\n",
    "    Embedding(input_dim=len(INPUT_CHARS) + 1,\n",
    "              output_dim=embedding_size,\n",
    "              input_shape=[None]),\n",
    "    LSTM(128)\n",
    "])\n",
    "\n",
    "decoder = Sequential([\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model = Sequential([\n",
    "    encoder,\n",
    "    RepeatVector(max_output_length),\n",
    "    decoder\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 28s 72ms/step - loss: 2.0745 - accuracy: 0.2670 - val_loss: 1.3249 - val_accuracy: 0.5131\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 1.2491 - accuracy: 0.5461 - val_loss: 1.1542 - val_accuracy: 0.5917\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.9757 - accuracy: 0.6487 - val_loss: 0.8474 - val_accuracy: 0.6881\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.7295 - accuracy: 0.7304 - val_loss: 0.6402 - val_accuracy: 0.7617\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 17s 53ms/step - loss: 0.5570 - accuracy: 0.7899 - val_loss: 0.4810 - val_accuracy: 0.8158\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 15s 48ms/step - loss: 0.3843 - accuracy: 0.8523 - val_loss: 0.2683 - val_accuracy: 0.9026\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 15s 48ms/step - loss: 0.2663 - accuracy: 0.9109 - val_loss: 0.2932 - val_accuracy: 0.9140\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.2100 - accuracy: 0.9418 - val_loss: 0.1129 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 16s 50ms/step - loss: 0.0925 - accuracy: 0.9811 - val_loss: 0.0638 - val_accuracy: 0.9884\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 0.0508 - accuracy: 0.9929 - val_loss: 0.0385 - val_accuracy: 0.9940\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 0.0298 - accuracy: 0.9970 - val_loss: 0.0246 - val_accuracy: 0.9970\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.0186 - accuracy: 0.9988 - val_loss: 0.0162 - val_accuracy: 0.9985\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.0119 - accuracy: 0.9995 - val_loss: 0.0109 - val_accuracy: 0.9994\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.0079 - accuracy: 0.9999 - val_loss: 0.0076 - val_accuracy: 0.9997\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9998\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9998\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9999\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9999\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "optimizer = Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n",
    "    return [\"\".join([(\"?\" + chars)[index] for index in sequence])\n",
    "            for sequence in ids]"
   ]
  },
  {
   "source": [
    "X_new = prepare_date_strs([\"September 17, 2009\", \"July 14, 1789\"])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2009-09-17\n1789-07-14\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "source": [
    "X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-02-02\n1789-01-14\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = X_train.shape[1]\n",
    "\n",
    "def prepare_date_strs_padded(date_strs):\n",
    "    X = prepare_date_strs(date_strs)\n",
    "    if X.shape[1] < max_input_length:\n",
    "        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n",
    "    return X\n",
    "\n",
    "def convert_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    #ids = model.predict_classes(X)\n",
    "    ids = np.argmax(model.predict(X), axis=-1)\n",
    "    return ids_to_date_strs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['2020-05-02', '1789-07-14']"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "convert_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  }
 ]
}